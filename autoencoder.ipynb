{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ST ARCHITECTURE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# CIFAR-10 Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Autoencoder with Classification Head\n",
    "class AutoencoderWithClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoencoderWithClassifier, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  # (64, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # (128, 8, 8)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # (256, 4, 4)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # (128, 8, 8)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # (64, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  # (3, 32, 32)\n",
    "            nn.Tanh()  # Normalize to [-1, 1]\n",
    "        )\n",
    "        # Classification Head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 512),  # Flattened size: 256 * 4 * 4\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)  # 10 classes for CIFAR-10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        logits = self.classifier(encoded.view(encoded.size(0), -1))  # Flatten before classifier\n",
    "        return decoded, logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = AutoencoderWithClassifier().to(device)\n",
    "\n",
    "reconstruction_loss = nn.MSELoss()\n",
    "classification_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "correct_classwise = torch.zeros(10)  # To count correct predictions per class\n",
    "total_classwise = torch.zeros(10)    # To count total samples per class\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        decoded, logits = model(images)\n",
    "        loss_recon = reconstruction_loss(decoded, images)\n",
    "        loss_class = classification_loss(logits, labels)\n",
    "        loss = loss_recon + loss_class  # Combined loss\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Count accuracy per class\n",
    "        for i in range(len(labels)):\n",
    "            total_classwise[labels[i]] += 1\n",
    "            correct_classwise[labels[i]] += (predicted[i] == labels[i]).item()\n",
    "    \n",
    "    train_accuracy = total_correct / total_samples * 100\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "reconstruction_losses = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        decoded, logits = model(images)\n",
    "\n",
    "        # Compute classification accuracy\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Compute reconstruction loss\n",
    "        loss_recon = reconstruction_loss(decoded, images)\n",
    "        reconstruction_losses.append(loss_recon.item())\n",
    "\n",
    "test_accuracy = total_correct / total_samples * 100\n",
    "average_reconstruction_loss = sum(reconstruction_losses) / len(reconstruction_losses)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%, Average Reconstruction Loss: {average_reconstruction_loss:.4f}\")\n",
    "\n",
    "# Visualizing original and reconstructed images\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        decoded, _ = model(images)\n",
    "        break\n",
    "\n",
    "fig, axs = plt.subplots(2, 8, figsize=(12, 4))\n",
    "for i in range(8):\n",
    "    axs[0, i].imshow(np.transpose((images[i].cpu().numpy() * 0.5 + 0.5), (1, 2, 0)))  # Denormalize\n",
    "    axs[1, i].imshow(np.transpose((decoded[i].cpu().numpy() * 0.5 + 0.5), (1, 2, 0)))\n",
    "    axs[0, i].axis('off')\n",
    "    axs[1, i].axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "class_accuracies = correct_classwise / total_classwise * 100\n",
    "# Print the accuracy for each class\n",
    "for i in range(10):\n",
    "    print(f'Accuracy for class {train_dataset.classes[i]}: {class_accuracies[i]:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND ARCHITECTURE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# CIFAR-10 Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Autoencoder with Classification Head\n",
    "class AutoencoderWithClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoencoderWithClassifier, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),   \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=1, padding=1),    \n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # Classification Head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 4 * 4, 512),  # Flattened size: 256 * 4 * 4\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)  # 10 classes for CIFAR-10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        logits = self.classifier(encoded.view(encoded.size(0), -1))  # Flatten before classifier\n",
    "        return decoded, logits\n",
    "\n",
    "\n",
    "model = AutoencoderWithClassifier().to(device)\n",
    "\n",
    "reconstruction_loss = nn.MSELoss()\n",
    "classification_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        decoded, logits = model(images)\n",
    "        loss_recon = reconstruction_loss(decoded, images)\n",
    "        loss_class = classification_loss(logits, labels)\n",
    "        loss = loss_recon + loss_class  # Combined loss\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track accuracy\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    train_accuracy = total_correct / total_samples * 100\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "reconstruction_losses = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        decoded, logits = model(images)\n",
    "\n",
    "        # Compute classification accuracy\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Compute reconstruction loss\n",
    "        loss_recon = reconstruction_loss(decoded, images)\n",
    "        reconstruction_losses.append(loss_recon.item())\n",
    "\n",
    "test_accuracy = total_correct / total_samples * 100\n",
    "average_reconstruction_loss = sum(reconstruction_losses) / len(reconstruction_losses)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%, Average Reconstruction Loss: {average_reconstruction_loss:.4f}\")\n",
    "\n",
    "# Visualizing original and reconstructed images\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        decoded, _ = model(images)\n",
    "        break\n",
    "\n",
    "fig, axs = plt.subplots(2, 8, figsize=(12, 4))\n",
    "for i in range(8):\n",
    "    axs[0, i].imshow(np.transpose((images[i].cpu().numpy() * 0.5 + 0.5), (1, 2, 0)))  # Denormalize\n",
    "    axs[1, i].imshow(np.transpose((decoded[i].cpu().numpy() * 0.5 + 0.5), (1, 2, 0)))\n",
    "    axs[0, i].axis('off')\n",
    "    axs[1, i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3RD ARCHITECTURE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# CIFAR-10 Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Autoencoder with Classification Head\n",
    "class AutoencoderWithClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoencoderWithClassifier, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # (64, 32, 32)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # (128, 16, 16)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # (256, 8, 8)\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),  # (512, 4, 4)\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),  # (256, 8, 8)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # (128, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),   # (64, 32, 32)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=1, padding=1),     # (3, 32, 32)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 4 * 4, 512),  # Flattened size: 512 * 4 * 4\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)  # 10 classes for CIFAR-10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        logits = self.classifier(encoded.view(encoded.size(0), -1))  # Flatten before classifier\n",
    "        return decoded, logits\n",
    "\n",
    "\n",
    "\n",
    "model = AutoencoderWithClassifier().to(device)\n",
    "\n",
    "reconstruction_loss = nn.MSELoss()\n",
    "classification_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        decoded, logits = model(images)\n",
    "        loss_recon = reconstruction_loss(decoded, images)\n",
    "        loss_class = classification_loss(logits, labels)\n",
    "        loss = loss_recon + loss_class  # Combined loss\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track accuracy\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    train_accuracy = total_correct / total_samples * 100\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "reconstruction_losses = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        decoded, logits = model(images)\n",
    "\n",
    "        # Compute classification accuracy\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Compute reconstruction loss\n",
    "        loss_recon = reconstruction_loss(decoded, images)\n",
    "        reconstruction_losses.append(loss_recon.item())\n",
    "\n",
    "test_accuracy = total_correct / total_samples * 100\n",
    "average_reconstruction_loss = sum(reconstruction_losses) / len(reconstruction_losses)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%, Average Reconstruction Loss: {average_reconstruction_loss:.4f}\")\n",
    "\n",
    "# Visualizing original and reconstructed images\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        decoded, _ = model(images)\n",
    "        break\n",
    "\n",
    "fig, axs = plt.subplots(2, 8, figsize=(12, 4))\n",
    "for i in range(8):\n",
    "    axs[0, i].imshow(np.transpose((images[i].cpu().numpy() * 0.5 + 0.5), (1, 2, 0)))  # Denormalize\n",
    "    axs[1, i].imshow(np.transpose((decoded[i].cpu().numpy() * 0.5 + 0.5), (1, 2, 0)))\n",
    "    axs[0, i].axis('off')\n",
    "    axs[1, i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Get a batch of data for PCA\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Convert images to numpy array for PCA\n",
    "images_np = images.view(images.size(0), -1).numpy()\n",
    "\n",
    "\n",
    "# PCA\n",
    "n_components = 40  \n",
    "pca = PCA(n_components=n_components)\n",
    "images_pca = pca.fit_transform(images_np)  \n",
    "images_reconstructed = pca.inverse_transform(images_pca)  \n",
    "\n",
    "# Reshape reconstructed images back to original shape\n",
    "images_reconstructed = torch.tensor(images_reconstructed).view(-1, 3, 32, 32)\n",
    "\n",
    "# Visualize results\n",
    "def plot_images(original, reconstructed, n=5):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    for i in range(n):\n",
    "        # Original\n",
    "        plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(original[i].permute(1, 2, 0) * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        if i == n // 2:\n",
    "            plt.title('Original Images')\n",
    "\n",
    "        # Reconstructed\n",
    "        plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(reconstructed[i].permute(1, 2, 0).detach().numpy() * 0.5 + 0.5)\n",
    "        plt.axis('off')\n",
    "        if i == n // 2:\n",
    "            plt.title('Reconstructed Images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some examples\n",
    "plot_images(images, images_reconstructed)\n",
    "\n",
    "\n",
    "# PCA transformation of the full dataset (training set)\n",
    "def transform_data_with_pca(data_loader):\n",
    "    pca_data = []\n",
    "    labels_data = []\n",
    "    for images, labels in data_loader:\n",
    "        images_np = images.view(images.size(0), -1).numpy()\n",
    "        images_pca = pca.transform(images_np) \n",
    "        pca_data.append(torch.tensor(images_pca))\n",
    "        labels_data.append(labels)\n",
    "    \n",
    "    # Combine all batches\n",
    "    pca_data = torch.cat(pca_data, dim=0)\n",
    "    labels_data = torch.cat(labels_data, dim=0)\n",
    "    \n",
    "    return pca_data, labels_data\n",
    "\n",
    "# Apply PCA transformation to train and test data\n",
    "train_data_pca, train_labels = transform_data_with_pca(train_loader)\n",
    "test_data_pca, test_labels = transform_data_with_pca(test_loader)\n",
    "\n",
    "# Classifier neural network\n",
    "class ClassifierNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifierNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_components, 512)  # Input size is PCA components after the transform\n",
    "        self.fc2 = nn.Linear(512, 10)  # 10 output classes for CIFAR-10\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ClassifierNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Convert PCA-transformed data to device tensors\n",
    "train_data_pca = train_data_pca.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "test_data_pca = test_data_pca.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "\n",
    "\n",
    "correct_classwise = torch.zeros(10)  # To count correct predictions per class\n",
    "total_classwise = torch.zeros(10)    # To count total samples per class\n",
    " \n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(0, len(train_data_pca), 100):\n",
    "        images = train_data_pca[i:i+100]\n",
    "        labels = train_labels[i:i+100]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Count accuracy per class\n",
    "        for i in range(len(labels)):\n",
    "            total_classwise[labels[i]] += 1\n",
    "            correct_classwise[labels[i]] += (predicted[i] == labels[i]).item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_data_pca):.4f}, Accuracy: {(correct * 100) / total:.2f}%\")\n",
    "\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_data_pca), 100):\n",
    "        images = test_data_pca[i:i+100]\n",
    "        labels = test_labels[i:i+100]\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {(correct * 100) / total:.2f}%\")\n",
    "\n",
    "class_accuracies = correct_classwise / total_classwise * 100\n",
    "# Print the accuracy for each class\n",
    "for i in range(10):\n",
    "    print(f'Accuracy for class {trainset.classes[i]}: {class_accuracies[i]:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
